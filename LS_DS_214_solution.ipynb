{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_214_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikibhatt/DS-Unit-2-Linear-Models/blob/master/LS_DS_214_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ3dfijFGiUI",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "- [ ] Watch Aaron's [video #1](https://www.youtube.com/watch?v=pREaWFli-5I) (12 minutes) & [video #2](https://www.youtube.com/watch?v=bDQgVt4hFgY) (9 minutes) to learn about the mathematics of Logistic Regression.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuAHBu7CGiUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFiNtkL0GiUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EReV1A5OGiUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ME7QGDRGiUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiQIp4FKGiUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2k64bQNRyMx",
        "colab_type": "text"
      },
      "source": [
        "# Do train/validate/test split. \n",
        "\n",
        "Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "padJD7TXGiUZ",
        "colab_type": "code",
        "outputId": "ea89b00b-2324-41af-c743-90ff33b8641d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California  1/18/2016   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California  1/24/2016   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California  1/27/2016   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHKkXw-bR1X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vMq5YKzR8i6",
        "colab_type": "code",
        "outputId": "9cafc8ed-6b78-429b-cd7c-21e12b37c9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = df[df.Date.dt.year <= 2016]\n",
        "val = df[df.Date.dt.year == 2017]\n",
        "test = df[df.Date.dt.year >= 2018]\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 59), (85, 59), (38, 59))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuLQGMHUSTn1",
        "colab_type": "text"
      },
      "source": [
        "# Begin with baselines for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHUjdJVDSNVp",
        "colab_type": "code",
        "outputId": "5dd017f0-a6b6-4de3-9176-43b296ea7a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "target = 'Great'\n",
        "train[target].value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.590604\n",
              "True     0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd1MphLoSkz7",
        "colab_type": "text"
      },
      "source": [
        "The target is `Great`. Its majority class is `False`, which occurs with 59% frequency in the train set. Therefore, the majority class baseline accuracy is 59%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS5gaZenUdMT",
        "colab_type": "text"
      },
      "source": [
        "# Use scikit-learn for Logistic Regression\n",
        "\n",
        "# Get your model's validation accuracy. \n",
        "\n",
        "(Multiple times if you try multiple iterations.)\n",
        "\n",
        "# Stretch goal: Do feature scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WawWKSYSjHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can start with a subset of features. \n",
        "# For example, we can try these 10 numeric features:\n",
        "\n",
        "# The 10-dimensional burrito\n",
        "# Contrary to popular belief, burritos do not merely exist in 3 dimensions. \n",
        "# They transcend the physical limitations of space. From polling several San \n",
        "# Diegans, weâ€™ve established the 10 core dimensions of the San Diego burrito.\n",
        "features = ['Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings', \n",
        "            'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap']\n",
        "\n",
        "\n",
        "# Assign to X, y\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftf3sMBUUmIc",
        "colab_type": "code",
        "outputId": "f602ede8-095a-43b0-b064-5ff3c3617527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "\n",
        "model = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8823529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6hXLnJrZ_Jz",
        "colab_type": "text"
      },
      "source": [
        "# Stretch goal: Do one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQQCI4N2ZVwT",
        "colab_type": "code",
        "outputId": "cd1cd9e1-5f97-40ff-c252-e3b2d74a1e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "# What if we tried all the features?\n",
        "features = train.columns.drop([target, 'Date'])\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_imputed)\n",
        "\n",
        "model = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7647058823529411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azH43gjHY0Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr(train, val, features):\n",
        "    \"\"\"\n",
        "    Try features (a list) and make a Logistic Regression model.\n",
        "    Also provide train & val dataframes.\n",
        "    The function returns a validation score.\n",
        "    \"\"\"\n",
        "\n",
        "    X_train = train[features]\n",
        "    X_val = val[features]\n",
        "\n",
        "    encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "    X_train_encoded = encoder.fit_transform(X_train)\n",
        "    X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "    imputer = SimpleImputer()\n",
        "    X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "    X_val_imputed = imputer.transform(X_val_encoded)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "    X_val_scaled = scaler.transform(X_val_imputed)\n",
        "\n",
        "    model = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    return model.score(X_val_scaled, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRebYn58ZYfI",
        "colab_type": "code",
        "outputId": "deef0b82-1fda-4cf4-c03b-66ce4a52cd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr(train, val, features=['Synergy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8117647058823529"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu8Y752xZkGr",
        "colab_type": "code",
        "outputId": "09c75105-23e3-4724-86eb-97497cf57358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr(train, val, features=['Volume', 'Temp'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.611764705882353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoYFziHBZtI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bBdjsaUaOX5",
        "colab_type": "text"
      },
      "source": [
        "The score is worse!\n",
        "\n",
        "We can go back to the previous model, or iterate and try more possibilities. I'll do the former.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP-s8CeAbNSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['Volume', 'Tortilla', 'Temp', 'Meat', 'Fillings', \n",
        "            'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap']\n",
        "\n",
        "X_train = train[features]\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "\n",
        "model = LogisticRegressionCV(cv=5, n_jobs=-1, random_state=42)\n",
        "model.fit(X_train_scaled, y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cAGnTTnazf1",
        "colab_type": "text"
      },
      "source": [
        "# Get your model's test accuracy. \n",
        "\n",
        "(One time, at the end.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FblstygaZpYj",
        "colab_type": "code",
        "outputId": "95e2319b-5173-4f94-8617-7b299ea1548e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "print('Test Accuracy', model.score(X_test_scaled, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.7894736842105263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp2KPW_gbhMD",
        "colab_type": "text"
      },
      "source": [
        "It's not surprising or concerning that the Test accuracy is different than and lower than the Validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbzF7y5zbyq9",
        "colab_type": "text"
      },
      "source": [
        "# Stretch goal: Get and plot your coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuqrwnU8bfKN",
        "colab_type": "code",
        "outputId": "d879e9b0-63f2-42f6-e08d-f3d7819d3400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "%matplotlib inline\n",
        "coefficients = pd.Series(model.coef_[0], features)\n",
        "coefficients.sort_values().plot.barh();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD4CAYAAADYU1DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wglCukSdcmyp",
        "colab_type": "text"
      },
      "source": [
        "The top 3 features correlated with [great burritos](https://srcole.github.io/100burritos/) in this linear model:\n",
        "\n",
        "> - Flavor synergy - \"That magical aspect a great burrito has, making everything come together like it is a gift from the skies\"\n",
        "> - Non-meat filling quality\n",
        "> - Meat quality"
      ]
    }
  ]
}